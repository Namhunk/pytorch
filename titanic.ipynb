{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5314a28f-b2ef-451e-83fd-2da5c0761a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20274a09-cb39-482e-9c40-8682dbd2ac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./titanic/train.csv')\n",
    "df_test = pd.read_csv('./titanic/test.csv')\n",
    "df_sub = pd.read_csv('./titanic/gender_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb5b0e75-57db-4baa-8127-714e26813489",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "df_test.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "\n",
    "sex = pd.get_dummies(df_train['Sex'], drop_first=True)\n",
    "embark = pd.get_dummies(df_train['Embarked'], drop_first=True)\n",
    "df_train = pd.concat([df_train, sex, embark], axis=1)\n",
    "df_train.drop(['Sex', 'Embarked'], axis=1, inplace=True)\n",
    "\n",
    "sex = pd.get_dummies(df_test['Sex'], drop_first=True)\n",
    "embark = pd.get_dummies(df_test['Embarked'], drop_first=True)\n",
    "df_test = pd.concat([df_test, sex, embark], axis=1)\n",
    "df_test.drop(['Sex', 'Embarked'], axis=1, inplace=True)\n",
    "\n",
    "df_train.fillna(df_train.mean(), inplace=True)\n",
    "df_test.fillna(df_test.mean(), inplace=True)\n",
    "\n",
    "Scaler1 = StandardScaler()\n",
    "Scaler2 = StandardScaler()\n",
    "\n",
    "train_columns = df_train.columns\n",
    "test_columns = df_test.columns\n",
    "\n",
    "df_train = pd.DataFrame(Scaler1.fit_transform(df_train))\n",
    "df_test = pd.DataFrame(Scaler2.fit_transform(df_test))\n",
    "\n",
    "df_train.columns = train_columns\n",
    "df_test.columns = test_columns\n",
    "\n",
    "x_train = df_train.iloc[:, 2:].values\n",
    "y_train = df_train.loc[:, 'Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fced468-b943-4d64-bad6-6a476c9989a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "device = torch.device('mps:0' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2992f257-f270-4b70-9b59-b9394ac73633",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "train_dataset = TitanicDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "41ffb359-ef65-41ec-a7a3-ae922eb4150f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=8, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(8, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 64)\n",
    "        self.fc4 = nn.Linear(64, 2)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "model = Net().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0f17ab99-e531-4326-9b67-e7d218b7fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "080be5a0-60d9-4a27-ac63-c32a0d35c0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf -> 0.243769). Saving the model..\n",
      "Validation loss decreased (0.243769 -> 0.228435). Saving the model..\n",
      "Validation loss decreased (0.228435 -> 0.225800). Saving the model..\n",
      "Validation loss decreased (0.225800 -> 0.214875). Saving the model..\n",
      "Validation loss decreased (0.214875 -> 0.210970). Saving the model..\n",
      "Validation loss decreased (0.210970 -> 0.210644). Saving the model..\n",
      "Validation loss decreased (0.210644 -> 0.210495). Saving the model..\n",
      "Validation loss decreased (0.210495 -> 0.200579). Saving the model..\n",
      "Epoch: 100 \tTraining Loss: 0.201792 \tTraining Accuracy: 90.46%\n",
      "Validation loss decreased (0.200579 -> 0.196435). Saving the model..\n",
      "Validation loss decreased (0.196435 -> 0.193713). Saving the model..\n",
      "Validation loss decreased (0.193713 -> 0.192775). Saving the model..\n",
      "Epoch: 200 \tTraining Loss: 0.201501 \tTraining Accuracy: 91.69%\n",
      "Validation loss decreased (0.192775 -> 0.184310). Saving the model..\n",
      "Validation loss decreased (0.184310 -> 0.180078). Saving the model..\n",
      "Epoch: 300 \tTraining Loss: 0.200665 \tTraining Accuracy: 91.36%\n",
      "Epoch: 400 \tTraining Loss: 0.187780 \tTraining Accuracy: 91.36%\n",
      "Validation loss decreased (0.180078 -> 0.179662). Saving the model..\n",
      "Validation loss decreased (0.179662 -> 0.178612). Saving the model..\n",
      "Validation loss decreased (0.178612 -> 0.176612). Saving the model..\n",
      "Validation loss decreased (0.176612 -> 0.174988). Saving the model..\n",
      "Validation loss decreased (0.174988 -> 0.170477). Saving the model..\n",
      "Epoch: 500 \tTraining Loss: 0.182954 \tTraining Accuracy: 91.81%\n",
      "Training ended!\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "n_epochs = 500\n",
    "\n",
    "train_loss_min = np.Inf\n",
    "model.train()\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0.0\n",
    "    num_correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(torch.float32).to(device), target.to(torch.long).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "        predicted = torch.max(output, 1)[1]\n",
    "        num_correct += (predicted == target).sum().item()\n",
    "\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "\n",
    "    if train_loss <= train_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} -> {:.6f}). Saving the model..'\n",
    "              .format(train_loss_min, train_loss))\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "        train_loss_min = train_loss\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tTraining Accuracy: {:.2f}%'\n",
    "              .format(epoch + 1, train_loss, num_correct / len(train_loader.dataset) * 100))\n",
    "\n",
    "print('Training ended!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "463a67cb-a541-45cd-b8d7-87dfd86b9687",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.iloc[:, 1:].values\n",
    "x_test_var = Variable(torch.FloatTensor(x_test), requires_grad=False).to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_result = model(x_test_var)\n",
    "values, labels = torch.max(test_result, 1)\n",
    "survived = labels.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "907c0117-494b-4826-9ea8-1caa25c77f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PassengerId': df_sub['PassengerId'], 'Survived': survived})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1bdebf-d7f2-4295-92b8-93aabed96cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
